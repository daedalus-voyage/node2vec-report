{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PPI classification\n",
    "\n",
    "See https://docs.dgl.ai/generated/dgl.data.PPIDataset.html#dgl.data.PPIDataset\n",
    "See https://graphneural.network/datasets/#ppi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display_functions import clear_output, display\n",
    "from igraph import Graph, Vertex\n",
    "from networkx.readwrite import json_graph\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import csc_matrix\n",
    "from stellargraph import StellarGraph\n",
    "from tensorflow import keras\n",
    "\n",
    "from lib.DataSet import DataSet\n",
    "from lib.ProjectGraph import balance, largest_component\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Methods and functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "from stellargraph.layer import Node2Vec, link_classification\n",
    "from stellargraph.mapper import Node2VecLinkGenerator, Node2VecNodeGenerator\n",
    "from stellargraph.data import BiasedRandomWalk, UnsupervisedSampler\n",
    "\n",
    "\n",
    "class Word2VecResult:\n",
    "\n",
    "    embeddings = None\n",
    "\n",
    "    def __init__(self, embeddings):\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "def word2vec_run(graph: StellarGraph, **kwargs) -> Word2VecResult:\n",
    "\n",
    "    walker_config = {\n",
    "\n",
    "        # Defines default random walker config (used during testing)\n",
    "        'n': 5,            # n         --> total number of random walks per node\n",
    "        'length': 25,        # length    --> Maximum length of each random walk\n",
    "        'p': 1.0,           # p         --> Defines probability, 1/p, of returning to source node\n",
    "        'q': 1.0,           # q         --> Defines probability, 1/q, for moving to a node away from the source node\n",
    "\n",
    "        # overrides previous configurations\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "    # print(\"Q should be {}, but is {}\".format(kwargs['q'], walker_config['q']))\n",
    "\n",
    "    node2vec_config = {\n",
    "\n",
    "        # Node2Vec link generator config\n",
    "        'batch_size': 50,\n",
    "        'epochs': 2,\n",
    "        'embedding_size': 128,\n",
    "\n",
    "        'learning_rate': 1e-3,\n",
    "        'epsilon': 1e-7,\n",
    "        'momentum': 0.01,\n",
    "        'verbose': 0,\n",
    "\n",
    "        # overrides previous configurations\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "    # configure a random walker\n",
    "    walker = BiasedRandomWalk(\n",
    "        graph,\n",
    "        n=walker_config['n'],\n",
    "        length=walker_config['length'],\n",
    "        p=walker_config['p'],\n",
    "        q=walker_config['q'],\n",
    "    )\n",
    "\n",
    "    # sampler\n",
    "    unsupervised_samples = UnsupervisedSampler(graph, nodes=list(graph.nodes()), walker=walker)\n",
    "\n",
    "    #\n",
    "    generator = Node2VecLinkGenerator(graph, node2vec_config['batch_size'])\n",
    "\n",
    "    node2vec = Node2Vec(node2vec_config['embedding_size'], generator=generator)\n",
    "\n",
    "    x_inp, x_out = node2vec.in_out_tensors()\n",
    "\n",
    "    prediction = link_classification(\n",
    "        output_dim=1, output_act=\"sigmoid\", edge_embedding_method=\"dot\"\n",
    "    )(x_out)\n",
    "\n",
    "    sgd_optimizer = keras.optimizers.SGD(\n",
    "        learning_rate=node2vec_config['learning_rate'], momentum=node2vec_config['momentum'], nesterov=False, name=\"SGD\"\n",
    "    )\n",
    "    # adam_optimizer = keras.optimizers.Adam(learning_rate=node2vec_config['learning_rate'], epsilon=node2vec_config['epsilon'])\n",
    "    adam_optimizer = keras.optimizers.Adam(learning_rate=node2vec_config['learning_rate'])\n",
    "\n",
    "    model = keras.Model(inputs=x_inp, outputs=prediction)\n",
    "    model.compile(\n",
    "        optimizer=adam_optimizer,\n",
    "        loss=keras.losses.binary_crossentropy,\n",
    "        metrics=[keras.metrics.binary_accuracy],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        generator.flow(unsupervised_samples),\n",
    "        epochs=node2vec_config['epochs'],\n",
    "        verbose=node2vec_config['verbose'],\n",
    "        use_multiprocessing=False,\n",
    "        workers=4,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    #\n",
    "    # NODE PREDICTION MODEL\n",
    "    #\n",
    "\n",
    "    x_inp_src = x_inp[0]\n",
    "    x_out_src = x_out[0]\n",
    "    embedding_model = keras.Model(inputs=x_inp_src, outputs=x_out_src)\n",
    "\n",
    "    node_ids = graph.nodes()\n",
    "\n",
    "    node_gen = Node2VecNodeGenerator(graph, node2vec_config['batch_size']).flow(node_ids)\n",
    "    node_embeddings = embedding_model.predict(node_gen, workers=4, verbose=1)\n",
    "\n",
    "    return Word2VecResult(\n",
    "        embeddings=node_embeddings\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classification"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PredictionPerformance:\n",
    "\n",
    "    description: str\n",
    "    accuracy: float\n",
    "    f1_micro: float\n",
    "    f1_macro: float\n",
    "\n",
    "\n",
    "def predict_node_classes(X, y, description='Node prediction results', scoring=\"accuracy\", split=1) -> PredictionPerformance:\n",
    "\n",
    "    # X will hold the 128-dimensional input features\n",
    "    # X = node_embeddings\n",
    "    # y holds the corresponding target values\n",
    "    # y = np.array(labels)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7/split, test_size=0.3/split)\n",
    "    # print(\n",
    "    #     \"Array shapes:\\n X_train = {}\\n y_train = {}\\n X_test = {}\\n y_test = {}\".format(\n",
    "    #         X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    # training\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "    clf = LogisticRegressionCV(\n",
    "        Cs=10, cv=10, scoring=scoring, penalty=\"l2\", solver=\"liblinear\", verbose=False, multi_class=\"ovr\", max_iter=300\n",
    "    )\n",
    "    # clf = LogisticRegression(\n",
    "    #     penalty=\"l2\", solver=\"liblinear\", verbose=False, multi_class=\"ovr\", max_iter=100\n",
    "    # )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predicting\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # scoring\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    return PredictionPerformance(\n",
    "        description=description,\n",
    "        accuracy=accuracy_score(y_test, y_pred),\n",
    "        f1_micro=f1_score(y_test, y_pred, average='micro'),\n",
    "        f1_macro=f1_score(y_test, y_pred, average='macro')\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GraphSAGE PPI dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_ppi_data(only_largest_component: bool = False) -> StellarGraph:\n",
    "\n",
    "    # load data\n",
    "    json_file = open('./data/ppi/ppi-G.json')\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "    # load into nxGraph\n",
    "    graph: nx.Graph = json_graph.node_link_graph(json_data)\n",
    "\n",
    "    # convert into stellargraph\n",
    "    stellar_graph = StellarGraph.from_networkx(graph)\n",
    "\n",
    "    # for this project, we want only the largest component\n",
    "    if only_largest_component:\n",
    "        largest_component_nodes = next(stellar_graph.connected_components())\n",
    "        stellar_graph = stellar_graph.subgraph(largest_component_nodes)\n",
    "\n",
    "    return stellar_graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_ppi_labels(graph: StellarGraph) -> np.array:\n",
    "\n",
    "    # reading the json file\n",
    "    class_map_file = open('./data/ppi/ppi-class_map.json')\n",
    "    class_map_dict = json.load(class_map_file)\n",
    "\n",
    "    # generating a label matrix\n",
    "    labels = np.array([class_map_dict[str(n)] for n in graph.nodes()])\n",
    "\n",
    "    return labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "83520/83520 [==============================] - 278s 3ms/step - loss: 0.6163 - binary_accuracy: 0.6445\n",
      "Epoch 2/2\n",
      "83520/83520 [==============================] - 310s 4ms/step - loss: 0.5599 - binary_accuracy: 0.7144\n",
      "70/70 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "length = 7\n",
    "\n",
    "ppi_graph = get_ppi_data(only_largest_component=True)\n",
    "ppi_results: Word2VecResult = word2vec_run(ppi_graph, n=n, length=length, p=0.5, q=9.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# load label data\n",
    "ppi_labels = get_ppi_labels(ppi_graph)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 147256 is out of bounds for axis 0 with size 3480",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m ppi_labels \u001B[38;5;241m=\u001B[39m get_ppi_labels(ppi_graph)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# balance the categories (true/false)\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m balanced_embeddings, balanced_labels \u001B[38;5;241m=\u001B[39m \u001B[43mbalance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mppi_results\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mppi_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# measure accuracy\u001B[39;00m\n\u001B[1;32m      8\u001B[0m accuracy \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/Projects/MAI/node2vec-report/lib/ProjectGraph.py:110\u001B[0m, in \u001B[0;36mbalance\u001B[0;34m(X, y)\u001B[0m\n\u001B[1;32m    106\u001B[0m negatives_indices_samples \u001B[38;5;241m=\u001B[39m sample_without_replacement(n_population\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39msize(negatives_indices), n_samples\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39msize(positives_indices))\n\u001B[1;32m    108\u001B[0m balanced_indices \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(negatives_indices_samples, positives_indices)\n\u001B[0;32m--> 110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbalanced_indices\u001B[49m\u001B[43m]\u001B[49m, y[balanced_indices]\n",
      "\u001B[0;31mIndexError\u001B[0m: index 147256 is out of bounds for axis 0 with size 3480"
     ]
    }
   ],
   "source": [
    "# balance the categories (true/false)\n",
    "balanced_embeddings, balanced_labels = balance(ppi_results.embeddings, ppi_labels)\n",
    "\n",
    "# measure accuracy\n",
    "accuracy = []\n",
    "for i in np.arange(1,100):\n",
    "    classification_performance = predict_node_classes(balanced_embeddings, balanced_labels)\n",
    "    accuracy = np.append(accuracy, [classification_performance.accuracy])\n",
    "\n",
    "np.mean(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Node2Vec PPI dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "def get_hosap_labels(only_largest_category: bool = False) -> np.array:\n",
    "\n",
    "    # load adjacency matrix data\n",
    "    hs = loadmat('./data/Homo_sapiens.mat', matlab_compatible=True)\n",
    "\n",
    "    group = np.array(csc_matrix(hs['group'], dtype=float).toarray())\n",
    "\n",
    "    if only_largest_category:\n",
    "\n",
    "        # find out index of largest group\n",
    "        group_sizes = np.sum(group, axis=0)\n",
    "        biggest_group_index = None\n",
    "        biggest_group_size = 0\n",
    "        for i, size in enumerate(group_sizes):\n",
    "            if size > biggest_group_size:\n",
    "                biggest_group_size = size\n",
    "                biggest_group_index = i\n",
    "\n",
    "        # resize groups\n",
    "        group = group[:,biggest_group_index]\n",
    "\n",
    "    return group"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "def get_hosap_graph(only_largest_component: bool = False) -> (Graph, StellarGraph, np.array):\n",
    "\n",
    "    # load adjacency matrix data\n",
    "    data = loadmat('./data/Homo_sapiens.mat', matlab_compatible=False)\n",
    "\n",
    "    network = np.array(csc_matrix(data['network'], dtype=float).toarray())\n",
    "    # group = np.array(csc_matrix(data['group'], dtype=int).toarray())\n",
    "    graph_labels = get_hosap_labels(only_largest_category=True)\n",
    "\n",
    "    # network_graph: Graph = Graph.Adjacency(csc_matrix(hs['network'], dtype=float), mode=\"undirected\")\n",
    "    nw_graph: Graph = Graph.Adjacency(network, mode=\"undirected\")\n",
    "\n",
    "    label_dict = []\n",
    "    label_index = []\n",
    "\n",
    "    # attach labels\n",
    "    for v in nw_graph.vs:\n",
    "        v: Vertex = v\n",
    "        v_id = v.index\n",
    "        v_label = graph_labels[v_id]\n",
    "        # print(v_label)\n",
    "        nw_graph.vs[v_id]['node_id'] = v_id\n",
    "        nw_graph.vs[v_id]['labels'] = [v_label]\n",
    "        label_dict.append(str(v_label))\n",
    "        label_index.append(str(v_id))\n",
    "        # break\n",
    "\n",
    "    if only_largest_component:\n",
    "        nw_graph = largest_component(nw_graph)\n",
    "\n",
    "    label_values = nw_graph.vs.get_attribute_values('labels')\n",
    "\n",
    "    # prepare graph data format\n",
    "    igraph_edges = np.array(nw_graph.get_edgelist())\n",
    "    stellar_edges = pd.DataFrame(data=igraph_edges, columns=['source', 'target'])\n",
    "    # stellartest = StellarGraph(edges=simple_edges, is_directed=False, nodes=group)\n",
    "    stellar_graph = StellarGraph.from_networkx(nw_graph.to_networkx(), node_features=\"labels\")\n",
    "    # stellar_graph = StellarGraph(edges=stellar_edges, is_directed=False, nodes=label_values)\n",
    "\n",
    "    # print(nw_graph.vs.attribute_names())\n",
    "\n",
    "    # for this project, we want only the largest component\n",
    "    # if only_largest_component:\n",
    "    #     largest_component_nodes = next(stellar_graph.connected_components())\n",
    "    #     stellar_graph = stellar_graph.subgraph(largest_component_nodes)\n",
    "\n",
    "    # construct label series\n",
    "    label_series = pd.Series(data=label_dict, index=label_index, name='category')\n",
    "\n",
    "    # return nw_graph, stellar_graph, np.array(label_values)[:,0]\n",
    "    return nw_graph, stellar_graph, label_series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n       ... \n3885    0.0\n3886    0.0\n3887    0.0\n3888    1.0\n3889    0.0\nName: category, Length: 3890, dtype: object"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igraph, stellargraph, labels = get_hosap_graph(only_largest_component=True)\n",
    "# print(igraph.summary())\n",
    "# print(stellargraph.info())\n",
    "# display(pd.DataFrame(labels, columns=['class']))\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "0          0\n1          1\n2          2\n3          3\n4          4\n        ... \n3847    3885\n3848    3886\n3849    3887\n3850    3888\n3851    3889\nName: node id, Length: 3852, dtype: int64"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(igraph.vs.get_attribute_values('node_id'), name='node id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "0       0.0\n1       0.0\n2       0.0\n3       0.0\n4       0.0\n       ... \n3847    0.0\n3848    0.0\n3849    0.0\n3850    1.0\n3851    0.0\nName: class, Length: 3852, dtype: float64"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels, name='class')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 24s 4ms/step - loss: 0.6565 - binary_accuracy: 0.5815\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 24s 4ms/step - loss: 0.6085 - binary_accuracy: 0.6314\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "n = 20\n",
    "length = 3\n",
    "\n",
    "hosap_igraph, hosap_stellar, labels = get_hosap_graph()\n",
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 7s 1ms/step - loss: 0.6970 - binary_accuracy: 0.5370\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 7s 1ms/step - loss: 0.6631 - binary_accuracy: 0.5772\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 8s 1ms/step - loss: 0.6854 - binary_accuracy: 0.5541\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 8s 1ms/step - loss: 0.6429 - binary_accuracy: 0.5995\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 11s 2ms/step - loss: 0.6714 - binary_accuracy: 0.5691\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 14s 2ms/step - loss: 0.6237 - binary_accuracy: 0.6165\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 25s 4ms/step - loss: 0.6571 - binary_accuracy: 0.5817\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 26s 4ms/step - loss: 0.6089 - binary_accuracy: 0.6308\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "6224/6224 [==============================] - 66s 10ms/step - loss: 0.6445 - binary_accuracy: 0.5911\n",
      "Epoch 2/2\n",
      "6224/6224 [==============================] - 64s 10ms/step - loss: 0.6042 - binary_accuracy: 0.6397\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=256)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "5640/6224 [==========================>...] - ETA: 14s - loss: 0.6466 - binary_accuracy: 0.5908"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [157]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m hosap_results: Word2VecResult \u001B[38;5;241m=\u001B[39m \u001B[43mword2vec_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhosap_stellar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mword2vec_run\u001B[0;34m(graph, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39mx_inp, outputs\u001B[38;5;241m=\u001B[39mprediction)\n\u001B[1;32m     73\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m     74\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39madam_optimizer,\n\u001B[1;32m     75\u001B[0m     loss\u001B[38;5;241m=\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mbinary_crossentropy,\n\u001B[1;32m     76\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[keras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mbinary_accuracy],\n\u001B[1;32m     77\u001B[0m )\n\u001B[0;32m---> 79\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43munsupervised_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode2vec_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# NODE PREDICTION MODEL\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     92\u001B[0m x_inp_src \u001B[38;5;241m=\u001B[39m x_inp[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/engine/training.py:1376\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1374\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m-> 1376\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39msteps():\n\u001B[1;32m   1377\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1378\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1379\u001B[0m         epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1380\u001B[0m         step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1381\u001B[0m         batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1382\u001B[0m         _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1383\u001B[0m       callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/engine/data_adapter.py:1246\u001B[0m, in \u001B[0;36mDataHandler.steps\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1244\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_insufficient_data:  \u001B[38;5;66;03m# Set by `catch_stop_iteration`.\u001B[39;00m\n\u001B[1;32m   1245\u001B[0m   \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1246\u001B[0m original_spe \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m   1247\u001B[0m can_run_full_execution \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1248\u001B[0m     original_spe \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[1;32m   1250\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inferred_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m\n\u001B[1;32m   1251\u001B[0m     original_spe)\n\u001B[1;32m   1253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_run_full_execution:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:674\u001B[0m, in \u001B[0;36mBaseResourceVariable.numpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnumpy\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    673\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 674\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m    675\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[1;32m    676\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy() is only available when eager execution is enabled.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:752\u001B[0m, in \u001B[0;36mBaseResourceVariable.read_value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    749\u001B[0m   value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_variable_op()\n\u001B[1;32m    750\u001B[0m \u001B[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001B[39;00m\n\u001B[1;32m    751\u001B[0m \u001B[38;5;66;03m# specifies instead of the device where the variable is.\u001B[39;00m\n\u001B[0;32m--> 752\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marray_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midentity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:149\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    146\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=1.0, embedding_size=512)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "93360/93360 [==============================] - 424s 5ms/step - loss: 0.5658 - binary_accuracy: 0.6856\n",
      "Epoch 2/2\n",
      "93360/93360 [==============================] - 380s 4ms/step - loss: 0.4981 - binary_accuracy: 0.7590\n",
      "78/78 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hosap_results: Word2VecResult = word2vec_run(hosap_stellar, n=n, length=length, p=0.5, q=9.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating performance of last run:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# balance the categories (true/false)\n",
    "balanced_embeddings, balanced_labels = balance(hosap_results.embeddings, labels[:,0])\n",
    "\n",
    "# measure accuracy\n",
    "accuracy = []\n",
    "f1_macro = []\n",
    "f1_micro = []\n",
    "for i in np.arange(1,100):\n",
    "    classification_performance = predict_node_classes(balanced_embeddings, balanced_labels)\n",
    "    accuracy = np.append(accuracy, [classification_performance.accuracy])\n",
    "    f1_macro = np.append(f1_macro, [classification_performance.f1_macro])\n",
    "    f1_micro = np.append(f1_micro, [classification_performance.f1_micro])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "data": {
      "text/plain": "0.715233139475564"
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "0.715233139475564"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_micro)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7133852091359285"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_macro)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "def experiment(graph: StellarGraph, graph_labels, n_values=[20], length_values=[3], q_values=[1.0], p_values=[1.0], embedding_size=128, classification_repeats=100, split=1) -> pd.DataFrame:\n",
    "    results = None\n",
    "    for n in n_values:\n",
    "        for length in length_values:\n",
    "            for q in q_values:\n",
    "                for p in p_values:\n",
    "\n",
    "                    # calculate embeddings\n",
    "                    word2vec_results: Word2VecResult = word2vec_run(graph, n=n, length=length, p=p, q=q, embedding_size=embedding_size)\n",
    "\n",
    "                    # experiment_balanced_embeddings, experiment_balanced_labels = balance(word2vec_results.embeddings, graph_labels)\n",
    "                    experiment_balanced_embeddings = word2vec_results.embeddings\n",
    "                    experiment_balanced_labels = graph_labels\n",
    "\n",
    "                    # predict and evaluate performance\n",
    "                    classification_accuracy = []\n",
    "                    classification_f1_macro = []\n",
    "                    classification_f1_micro = []\n",
    "                    for i in np.arange(1,classification_repeats):\n",
    "                        performance = predict_node_classes(experiment_balanced_embeddings, experiment_balanced_labels, scoring=\"f1_macro\", split=split)\n",
    "                        classification_accuracy = np.append(classification_accuracy, [performance.accuracy])\n",
    "                        classification_f1_macro = np.append(classification_f1_macro, [performance.f1_macro])\n",
    "                        classification_f1_micro = np.append(classification_f1_micro, [performance.f1_micro])\n",
    "\n",
    "                    # summarise performance\n",
    "                    avg_accuracy = np.mean(classification_accuracy)\n",
    "                    std_accuracy = np.std(classification_accuracy)\n",
    "                    avg_f1_micro = np.mean(classification_f1_micro)\n",
    "                    std_f1_micro = np.std(classification_f1_micro)\n",
    "                    avg_f1_macro = np.mean(classification_f1_macro)\n",
    "                    std_f1_macro = np.std(classification_f1_macro)\n",
    "\n",
    "                    # collect metrics\n",
    "                    metrics_data_row = np.array([[embedding_size, p, q, avg_accuracy, std_accuracy, avg_f1_micro, std_f1_micro, avg_f1_macro, std_f1_macro]])\n",
    "                    if results is None:\n",
    "                        results = metrics_data_row\n",
    "                    else:\n",
    "                        results = np.append(results, metrics_data_row, axis=0)\n",
    "\n",
    "                    results_table = pd.DataFrame(data=results, columns=['embedding size', 'p', 'q', 'accuracy (mean)', 'accuracy (std)', 'f1_micro (mean)', 'f1_micro (std)', 'f1_macro (mean)', 'f1_macro (std)'])\n",
    "\n",
    "                    clear_output(wait=True)\n",
    "                    display(results_table)\n",
    "\n",
    "    return results_table"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "data": {
      "text/plain": "  aa bb cc\n0  a  b  c\n1  a  b  c",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>aa</th>\n      <th>bb</th>\n      <th>cc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>b</td>\n      <td>c</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>b</td>\n      <td>c</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = np.array([['a', 'b', 'c']])\n",
    "# results = np.append(results, np.array([['a', 'b', 'c']]), axis = 0)\n",
    "# results = pd.DataFrame(data=results, columns=['aa', 'bb', 'cc'])\n",
    "# results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "hosap_igraph, hosap_stellar, hosap_labels = get_hosap_graph()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "   embedding size    p    q  accuracy (mean)  accuracy (std)  f1_micro (mean)  \\\n0            32.0  1.0  1.0         0.949562        0.003578         0.949562   \n\n   f1_micro (std)  f1_macro (mean)  f1_macro (std)  \n0        0.003578         0.487063        0.000941  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embedding size</th>\n      <th>p</th>\n      <th>q</th>\n      <th>accuracy (mean)</th>\n      <th>accuracy (std)</th>\n      <th>f1_micro (mean)</th>\n      <th>f1_micro (std)</th>\n      <th>f1_macro (mean)</th>\n      <th>f1_macro (std)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.949562</td>\n      <td>0.003578</td>\n      <td>0.949562</td>\n      <td>0.003578</td>\n      <td>0.487063</td>\n      <td>0.000941</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, embedding_size=32)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, embedding_size=64)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, embedding_size=128)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, embedding_size=256)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, embedding_size=512)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "    embedding size     p     q  accuracy (mean)  accuracy (std)  \\\n0             32.0   0.1   0.1         0.492297        0.028310   \n1             32.0   0.3   0.1         0.498827        0.032246   \n2             32.0   0.6   0.1         0.528415        0.027612   \n3             32.0   1.0   0.1         0.556729        0.030002   \n4             32.0   5.0   0.1         0.501020        0.027728   \n5             32.0  10.0   0.1         0.474696        0.031833   \n6             32.0   0.1   0.3         0.548515        0.032965   \n7             32.0   0.3   0.3         0.536119        0.033047   \n8             32.0   0.6   0.3         0.522702        0.028816   \n9             32.0   1.0   0.3         0.515356        0.028767   \n10            32.0   5.0   0.3         0.517957        0.032607   \n11            32.0  10.0   0.3         0.537802        0.029470   \n12            32.0   0.1   0.6         0.526579        0.027891   \n13            32.0   0.3   0.6         0.510764        0.031254   \n14            32.0   0.6   0.6         0.520253        0.032355   \n15            32.0   1.0   0.6         0.568411        0.027869   \n16            32.0   5.0   0.6         0.487705        0.029902   \n17            32.0  10.0   0.6         0.461126        0.031776   \n18            32.0   0.1   1.0         0.541781        0.027994   \n19            32.0   0.3   1.0         0.514692        0.030943   \n20            32.0   0.6   1.0         0.494949        0.031845   \n21            32.0   1.0   1.0         0.517702        0.029818   \n22            32.0   5.0   1.0         0.537292        0.030385   \n23            32.0  10.0   1.0         0.505357        0.026819   \n24            32.0   0.1   5.0         0.491429        0.032211   \n25            32.0   0.3   5.0         0.476482        0.027655   \n26            32.0   0.6   5.0         0.499592        0.029059   \n27            32.0   1.0   5.0         0.539027        0.028068   \n28            32.0   5.0   5.0         0.521477        0.029083   \n29            32.0  10.0   5.0         0.515611        0.031332   \n30            32.0   0.1  10.0         0.535558        0.026782   \n31            32.0   0.3  10.0         0.494949        0.028225   \n32            32.0   0.6  10.0         0.535405        0.023716   \n33            32.0   1.0  10.0         0.493368        0.028140   \n34            32.0   5.0  10.0         0.533109        0.030559   \n35            32.0  10.0  10.0         0.492807        0.031919   \n\n    f1_micro (mean)  f1_micro (std)  f1_macro (mean)  f1_macro (std)  \n0          0.492297        0.028310         0.489071        0.028346  \n1          0.498827        0.032246         0.495062        0.032036  \n2          0.528415        0.027612         0.523650        0.027174  \n3          0.556729        0.030002         0.552496        0.029483  \n4          0.501020        0.027728         0.489884        0.027841  \n5          0.474696        0.031833         0.471186        0.032144  \n6          0.548515        0.032965         0.544348        0.033463  \n7          0.536119        0.033047         0.531382        0.033067  \n8          0.522702        0.028816         0.518826        0.029428  \n9          0.515356        0.028767         0.510722        0.029631  \n10         0.517957        0.032607         0.514516        0.032555  \n11         0.537802        0.029470         0.534890        0.030059  \n12         0.526579        0.027891         0.521515        0.027782  \n13         0.510764        0.031254         0.507166        0.031597  \n14         0.520253        0.032355         0.513425        0.033908  \n15         0.568411        0.027869         0.566687        0.028290  \n16         0.487705        0.029902         0.485422        0.030497  \n17         0.461126        0.031776         0.457395        0.032149  \n18         0.541781        0.027994         0.538760        0.028626  \n19         0.514692        0.030943         0.510493        0.031057  \n20         0.494949        0.031845         0.490953        0.032069  \n21         0.517702        0.029818         0.512801        0.030211  \n22         0.537292        0.030385         0.531468        0.031316  \n23         0.505357        0.026819         0.500773        0.026766  \n24         0.491429        0.032211         0.485041        0.032331  \n25         0.476482        0.027655         0.468926        0.027799  \n26         0.499592        0.029059         0.495394        0.028305  \n27         0.539027        0.028068         0.530999        0.028785  \n28         0.521477        0.029083         0.516638        0.029753  \n29         0.515611        0.031332         0.512398        0.031243  \n30         0.535558        0.026782         0.531199        0.026947  \n31         0.494949        0.028225         0.492485        0.028229  \n32         0.535405        0.023716         0.531549        0.024740  \n33         0.493368        0.028140         0.485456        0.028369  \n34         0.533109        0.030559         0.528666        0.030125  \n35         0.492807        0.031919         0.482088        0.032199  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embedding size</th>\n      <th>p</th>\n      <th>q</th>\n      <th>accuracy (mean)</th>\n      <th>accuracy (std)</th>\n      <th>f1_micro (mean)</th>\n      <th>f1_micro (std)</th>\n      <th>f1_macro (mean)</th>\n      <th>f1_macro (std)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.492297</td>\n      <td>0.028310</td>\n      <td>0.492297</td>\n      <td>0.028310</td>\n      <td>0.489071</td>\n      <td>0.028346</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.498827</td>\n      <td>0.032246</td>\n      <td>0.498827</td>\n      <td>0.032246</td>\n      <td>0.495062</td>\n      <td>0.032036</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.528415</td>\n      <td>0.027612</td>\n      <td>0.528415</td>\n      <td>0.027612</td>\n      <td>0.523650</td>\n      <td>0.027174</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>0.556729</td>\n      <td>0.030002</td>\n      <td>0.556729</td>\n      <td>0.030002</td>\n      <td>0.552496</td>\n      <td>0.029483</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>0.1</td>\n      <td>0.501020</td>\n      <td>0.027728</td>\n      <td>0.501020</td>\n      <td>0.027728</td>\n      <td>0.489884</td>\n      <td>0.027841</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>0.1</td>\n      <td>0.474696</td>\n      <td>0.031833</td>\n      <td>0.474696</td>\n      <td>0.031833</td>\n      <td>0.471186</td>\n      <td>0.032144</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>0.548515</td>\n      <td>0.032965</td>\n      <td>0.548515</td>\n      <td>0.032965</td>\n      <td>0.544348</td>\n      <td>0.033463</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.536119</td>\n      <td>0.033047</td>\n      <td>0.536119</td>\n      <td>0.033047</td>\n      <td>0.531382</td>\n      <td>0.033067</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>0.3</td>\n      <td>0.522702</td>\n      <td>0.028816</td>\n      <td>0.522702</td>\n      <td>0.028816</td>\n      <td>0.518826</td>\n      <td>0.029428</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>0.515356</td>\n      <td>0.028767</td>\n      <td>0.515356</td>\n      <td>0.028767</td>\n      <td>0.510722</td>\n      <td>0.029631</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.517957</td>\n      <td>0.032607</td>\n      <td>0.517957</td>\n      <td>0.032607</td>\n      <td>0.514516</td>\n      <td>0.032555</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>0.3</td>\n      <td>0.537802</td>\n      <td>0.029470</td>\n      <td>0.537802</td>\n      <td>0.029470</td>\n      <td>0.534890</td>\n      <td>0.030059</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>0.6</td>\n      <td>0.526579</td>\n      <td>0.027891</td>\n      <td>0.526579</td>\n      <td>0.027891</td>\n      <td>0.521515</td>\n      <td>0.027782</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>0.6</td>\n      <td>0.510764</td>\n      <td>0.031254</td>\n      <td>0.510764</td>\n      <td>0.031254</td>\n      <td>0.507166</td>\n      <td>0.031597</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>0.6</td>\n      <td>0.520253</td>\n      <td>0.032355</td>\n      <td>0.520253</td>\n      <td>0.032355</td>\n      <td>0.513425</td>\n      <td>0.033908</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>0.6</td>\n      <td>0.568411</td>\n      <td>0.027869</td>\n      <td>0.568411</td>\n      <td>0.027869</td>\n      <td>0.566687</td>\n      <td>0.028290</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>0.6</td>\n      <td>0.487705</td>\n      <td>0.029902</td>\n      <td>0.487705</td>\n      <td>0.029902</td>\n      <td>0.485422</td>\n      <td>0.030497</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>0.6</td>\n      <td>0.461126</td>\n      <td>0.031776</td>\n      <td>0.461126</td>\n      <td>0.031776</td>\n      <td>0.457395</td>\n      <td>0.032149</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.541781</td>\n      <td>0.027994</td>\n      <td>0.541781</td>\n      <td>0.027994</td>\n      <td>0.538760</td>\n      <td>0.028626</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>1.0</td>\n      <td>0.514692</td>\n      <td>0.030943</td>\n      <td>0.514692</td>\n      <td>0.030943</td>\n      <td>0.510493</td>\n      <td>0.031057</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>1.0</td>\n      <td>0.494949</td>\n      <td>0.031845</td>\n      <td>0.494949</td>\n      <td>0.031845</td>\n      <td>0.490953</td>\n      <td>0.032069</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.517702</td>\n      <td>0.029818</td>\n      <td>0.517702</td>\n      <td>0.029818</td>\n      <td>0.512801</td>\n      <td>0.030211</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.537292</td>\n      <td>0.030385</td>\n      <td>0.537292</td>\n      <td>0.030385</td>\n      <td>0.531468</td>\n      <td>0.031316</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>0.505357</td>\n      <td>0.026819</td>\n      <td>0.505357</td>\n      <td>0.026819</td>\n      <td>0.500773</td>\n      <td>0.026766</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>5.0</td>\n      <td>0.491429</td>\n      <td>0.032211</td>\n      <td>0.491429</td>\n      <td>0.032211</td>\n      <td>0.485041</td>\n      <td>0.032331</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>5.0</td>\n      <td>0.476482</td>\n      <td>0.027655</td>\n      <td>0.476482</td>\n      <td>0.027655</td>\n      <td>0.468926</td>\n      <td>0.027799</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>5.0</td>\n      <td>0.499592</td>\n      <td>0.029059</td>\n      <td>0.499592</td>\n      <td>0.029059</td>\n      <td>0.495394</td>\n      <td>0.028305</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.539027</td>\n      <td>0.028068</td>\n      <td>0.539027</td>\n      <td>0.028068</td>\n      <td>0.530999</td>\n      <td>0.028785</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.521477</td>\n      <td>0.029083</td>\n      <td>0.521477</td>\n      <td>0.029083</td>\n      <td>0.516638</td>\n      <td>0.029753</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>0.515611</td>\n      <td>0.031332</td>\n      <td>0.515611</td>\n      <td>0.031332</td>\n      <td>0.512398</td>\n      <td>0.031243</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>32.0</td>\n      <td>0.1</td>\n      <td>10.0</td>\n      <td>0.535558</td>\n      <td>0.026782</td>\n      <td>0.535558</td>\n      <td>0.026782</td>\n      <td>0.531199</td>\n      <td>0.026947</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>32.0</td>\n      <td>0.3</td>\n      <td>10.0</td>\n      <td>0.494949</td>\n      <td>0.028225</td>\n      <td>0.494949</td>\n      <td>0.028225</td>\n      <td>0.492485</td>\n      <td>0.028229</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>32.0</td>\n      <td>0.6</td>\n      <td>10.0</td>\n      <td>0.535405</td>\n      <td>0.023716</td>\n      <td>0.535405</td>\n      <td>0.023716</td>\n      <td>0.531549</td>\n      <td>0.024740</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>0.493368</td>\n      <td>0.028140</td>\n      <td>0.493368</td>\n      <td>0.028140</td>\n      <td>0.485456</td>\n      <td>0.028369</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>0.533109</td>\n      <td>0.030559</td>\n      <td>0.533109</td>\n      <td>0.030559</td>\n      <td>0.528666</td>\n      <td>0.030125</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>32.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.492807</td>\n      <td>0.031919</td>\n      <td>0.492807</td>\n      <td>0.031919</td>\n      <td>0.482088</td>\n      <td>0.032199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_values = [20]\n",
    "length_values = [3]\n",
    "# q_values = np.array([0.2, 0.4, 0.6, 0.8, 1.0, 4.0, 7.0, 10.0])\n",
    "# p_values = np.array([0.2, 0.4, 0.6, 0.8, 1.0, 4.0, 7.0, 10.0])\n",
    "q_values = np.array([0.1, 0.3, 0.6, 1.0, 5.0, 10.0])\n",
    "p_values = np.array([0.1, 0.3, 0.6, 1.0, 5.0, 10.0])\n",
    "\n",
    "experiment_results_table = experiment(hosap_stellar, hosap_labels, n_values=n_values, length_values=length_values, p_values=p_values, q_values=q_values, embedding_size=32)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rr/p4lmjn152vj75lt21_txptlh0000gn/T/ipykernel_40687/3633795417.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  experiment_results_table.to_latex('./ppi-results-32.tex')\n"
     ]
    }
   ],
   "source": [
    "experiment_results_table.to_excel('./ppi-results-32.xlsx')\n",
    "experiment_results_table.to_pickle('./ppi-results-32.pkl')\n",
    "experiment_results_table.to_csv('./ppi-results-32.csv')\n",
    "experiment_results_table.to_latex('./ppi-results-32.tex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cora dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "from stellargraph.datasets import datasets\n",
    "\n",
    "\n",
    "def get_cora_graph() -> (StellarGraph, pd.Series):\n",
    "    dataset = datasets.Cora()\n",
    "    # display(HTML(dataset.description))\n",
    "    graph, subjects = dataset.load(largest_connected_component_only=True)\n",
    "\n",
    "    return graph, subjects"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.1, 0.3, 0.5, 0.7, 0.9, 1. , 3. , 5. , 7. , 9. ])"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(np.arange(0.1, 1.0, 0.2), np.arange(1.0, 10.0, 2.0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "data": {
      "text/plain": "    embedding size    p    q  accuracy (mean)  accuracy (std)  \\\n0             64.0  0.1  0.1         0.609626        0.027500   \n1             64.0  0.3  0.1         0.593583        0.041575   \n2             64.0  0.5  0.1         0.596554        0.024585   \n3             64.0  0.7  0.1         0.651812        0.054034   \n4             64.0  0.9  0.1         0.622103        0.026439   \n5             64.0  1.0  0.1         0.610220        0.042366   \n6             64.0  3.0  0.1         0.614379        0.035868   \n7             64.0  5.0  0.1         0.635175        0.034452   \n8             64.0  7.0  0.1         0.628045        0.030051   \n9             64.0  9.0  0.1         0.609031        0.028122   \n10            64.0  0.1  0.3         0.610814        0.039681   \n11            64.0  0.3  0.3         0.609626        0.037306   \n12            64.0  0.5  0.3         0.618538        0.028963   \n13            64.0  0.7  0.3         0.619133        0.035001   \n14            64.0  0.9  0.3         0.620915        0.031430   \n15            64.0  1.0  0.3         0.598336        0.060261   \n\n    f1_micro (mean)  f1_micro (std)  f1_macro (mean)  f1_macro (std)  \n0          0.609626        0.027500         0.576187        0.044834  \n1          0.593583        0.041575         0.573827        0.049040  \n2          0.596554        0.024585         0.562883        0.024755  \n3          0.651812        0.054034         0.619198        0.069280  \n4          0.622103        0.026439         0.596972        0.030680  \n5          0.610220        0.042366         0.579702        0.040723  \n6          0.614379        0.035868         0.583760        0.045510  \n7          0.635175        0.034452         0.601341        0.039992  \n8          0.628045        0.030051         0.586973        0.030312  \n9          0.609031        0.028122         0.589255        0.037117  \n10         0.610814        0.039681         0.583327        0.039622  \n11         0.609626        0.037306         0.578713        0.057186  \n12         0.618538        0.028963         0.583257        0.039205  \n13         0.619133        0.035001         0.579292        0.047177  \n14         0.620915        0.031430         0.590058        0.035520  \n15         0.598336        0.060261         0.563807        0.064856  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embedding size</th>\n      <th>p</th>\n      <th>q</th>\n      <th>accuracy (mean)</th>\n      <th>accuracy (std)</th>\n      <th>f1_micro (mean)</th>\n      <th>f1_micro (std)</th>\n      <th>f1_macro (mean)</th>\n      <th>f1_macro (std)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>64.0</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.609626</td>\n      <td>0.027500</td>\n      <td>0.609626</td>\n      <td>0.027500</td>\n      <td>0.576187</td>\n      <td>0.044834</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>64.0</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.593583</td>\n      <td>0.041575</td>\n      <td>0.593583</td>\n      <td>0.041575</td>\n      <td>0.573827</td>\n      <td>0.049040</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>64.0</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>0.596554</td>\n      <td>0.024585</td>\n      <td>0.596554</td>\n      <td>0.024585</td>\n      <td>0.562883</td>\n      <td>0.024755</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>64.0</td>\n      <td>0.7</td>\n      <td>0.1</td>\n      <td>0.651812</td>\n      <td>0.054034</td>\n      <td>0.651812</td>\n      <td>0.054034</td>\n      <td>0.619198</td>\n      <td>0.069280</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>64.0</td>\n      <td>0.9</td>\n      <td>0.1</td>\n      <td>0.622103</td>\n      <td>0.026439</td>\n      <td>0.622103</td>\n      <td>0.026439</td>\n      <td>0.596972</td>\n      <td>0.030680</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>0.610220</td>\n      <td>0.042366</td>\n      <td>0.610220</td>\n      <td>0.042366</td>\n      <td>0.579702</td>\n      <td>0.040723</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>64.0</td>\n      <td>3.0</td>\n      <td>0.1</td>\n      <td>0.614379</td>\n      <td>0.035868</td>\n      <td>0.614379</td>\n      <td>0.035868</td>\n      <td>0.583760</td>\n      <td>0.045510</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>64.0</td>\n      <td>5.0</td>\n      <td>0.1</td>\n      <td>0.635175</td>\n      <td>0.034452</td>\n      <td>0.635175</td>\n      <td>0.034452</td>\n      <td>0.601341</td>\n      <td>0.039992</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>64.0</td>\n      <td>7.0</td>\n      <td>0.1</td>\n      <td>0.628045</td>\n      <td>0.030051</td>\n      <td>0.628045</td>\n      <td>0.030051</td>\n      <td>0.586973</td>\n      <td>0.030312</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>64.0</td>\n      <td>9.0</td>\n      <td>0.1</td>\n      <td>0.609031</td>\n      <td>0.028122</td>\n      <td>0.609031</td>\n      <td>0.028122</td>\n      <td>0.589255</td>\n      <td>0.037117</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>64.0</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>0.610814</td>\n      <td>0.039681</td>\n      <td>0.610814</td>\n      <td>0.039681</td>\n      <td>0.583327</td>\n      <td>0.039622</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>64.0</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.609626</td>\n      <td>0.037306</td>\n      <td>0.609626</td>\n      <td>0.037306</td>\n      <td>0.578713</td>\n      <td>0.057186</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>64.0</td>\n      <td>0.5</td>\n      <td>0.3</td>\n      <td>0.618538</td>\n      <td>0.028963</td>\n      <td>0.618538</td>\n      <td>0.028963</td>\n      <td>0.583257</td>\n      <td>0.039205</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>64.0</td>\n      <td>0.7</td>\n      <td>0.3</td>\n      <td>0.619133</td>\n      <td>0.035001</td>\n      <td>0.619133</td>\n      <td>0.035001</td>\n      <td>0.579292</td>\n      <td>0.047177</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>64.0</td>\n      <td>0.9</td>\n      <td>0.3</td>\n      <td>0.620915</td>\n      <td>0.031430</td>\n      <td>0.620915</td>\n      <td>0.031430</td>\n      <td>0.590058</td>\n      <td>0.035520</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>64.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>0.598336</td>\n      <td>0.060261</td>\n      <td>0.598336</td>\n      <td>0.060261</td>\n      <td>0.563807</td>\n      <td>0.064856</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [248]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m q_values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m0.2\u001B[39m), np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m10.0\u001B[39m, \u001B[38;5;241m2.0\u001B[39m))\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# p_values = [1.0, 3.0, 5.0, 7.0]\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# q_values = [1.0]\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m experiment_results_table \u001B[38;5;241m=\u001B[39m \u001B[43mexperiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcora_stellar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcora_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlength_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassification_repeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m clear_output(wait\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m display(experiment_results_table)\n",
      "Input \u001B[0;32mIn [244]\u001B[0m, in \u001B[0;36mexperiment\u001B[0;34m(graph, graph_labels, n_values, length_values, q_values, p_values, embedding_size, classification_repeats)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m q_values:\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m p_values:\n\u001B[1;32m      7\u001B[0m \n\u001B[1;32m      8\u001B[0m         \u001B[38;5;66;03m# calculate embeddings\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m         word2vec_results: Word2VecResult \u001B[38;5;241m=\u001B[39m \u001B[43mword2vec_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgraph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlength\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m         \u001B[38;5;66;03m# experiment_balanced_embeddings, experiment_balanced_labels = balance(word2vec_results.embeddings, graph_labels)\u001B[39;00m\n\u001B[1;32m     12\u001B[0m         experiment_balanced_embeddings \u001B[38;5;241m=\u001B[39m word2vec_results\u001B[38;5;241m.\u001B[39membeddings\n",
      "Input \u001B[0;32mIn [165]\u001B[0m, in \u001B[0;36mword2vec_run\u001B[0;34m(graph, **kwargs)\u001B[0m\n\u001B[1;32m     73\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mModel(inputs\u001B[38;5;241m=\u001B[39mx_inp, outputs\u001B[38;5;241m=\u001B[39mprediction)\n\u001B[1;32m     74\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m     75\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39madam_optimizer,\n\u001B[1;32m     76\u001B[0m     loss\u001B[38;5;241m=\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mbinary_crossentropy,\n\u001B[1;32m     77\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[keras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mbinary_accuracy],\n\u001B[1;32m     78\u001B[0m )\n\u001B[0;32m---> 80\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflow\u001B[49m\u001B[43m(\u001B[49m\u001B[43munsupervised_samples\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode2vec_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mepochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnode2vec_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mverbose\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m# NODE PREDICTION MODEL\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     93\u001B[0m x_inp_src \u001B[38;5;241m=\u001B[39m x_inp[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/engine/training.py:1372\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1369\u001B[0m data_handler\u001B[38;5;241m.\u001B[39m_initial_epoch \u001B[38;5;241m=\u001B[39m (  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   1370\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001B[1;32m   1371\u001B[0m logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1372\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch, iterator \u001B[38;5;129;01min\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39menumerate_epochs():\n\u001B[1;32m   1373\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreset_metrics()\n\u001B[1;32m   1374\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/engine/data_adapter.py:1198\u001B[0m, in \u001B[0;36mDataHandler.enumerate_epochs\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1196\u001B[0m   data_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset)\n\u001B[1;32m   1197\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m epoch, data_iterator\n\u001B[0;32m-> 1198\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_epoch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/keras/engine/data_adapter.py:969\u001B[0m, in \u001B[0;36mKerasSequenceAdapter.on_epoch_end\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    967\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enqueuer:\n\u001B[1;32m    968\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enqueuer\u001B[38;5;241m.\u001B[39mstop()\n\u001B[0;32m--> 969\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_keras_sequence\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_epoch_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/stellargraph/mapper/sequences.py:333\u001B[0m, in \u001B[0;36mOnDemandLinkSequence.on_epoch_end\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;124;03mShuffle all link IDs at the end of each epoch\u001B[39;00m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshuffle:\n\u001B[0;32m--> 333\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_batches\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/stellargraph/mapper/sequences.py:326\u001B[0m, in \u001B[0;36mOnDemandLinkSequence._create_batches\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_create_batches\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwalker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/stellargraph/data/unsupervised_sampler.py:154\u001B[0m, in \u001B[0;36mUnsupervisedSampler.run\u001B[0;34m(self, batch_size)\u001B[0m\n\u001B[1;32m    149\u001B[0m sampling_distribution \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([degrees[n] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.75\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m all_nodes])\n\u001B[1;32m    150\u001B[0m sampling_distribution_norm \u001B[38;5;241m=\u001B[39m sampling_distribution \u001B[38;5;241m/\u001B[39m np\u001B[38;5;241m.\u001B[39msum(\n\u001B[1;32m    151\u001B[0m     sampling_distribution\n\u001B[1;32m    152\u001B[0m )\n\u001B[0;32m--> 154\u001B[0m walks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwalker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;66;03m# first item in each walk is the target/head node\u001B[39;00m\n\u001B[1;32m    157\u001B[0m targets \u001B[38;5;241m=\u001B[39m [walk[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m walk \u001B[38;5;129;01min\u001B[39;00m walks]\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/stellargraph/data/explorer.py:500\u001B[0m, in \u001B[0;36mBiasedRandomWalk.run\u001B[0;34m(self, nodes, n, length, p, q, seed, weighted)\u001B[0m\n\u001B[1;32m    498\u001B[0m mask \u001B[38;5;241m=\u001B[39m neighbours \u001B[38;5;241m==\u001B[39m previous_node\n\u001B[1;32m    499\u001B[0m weights[mask] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m ip\n\u001B[0;32m--> 500\u001B[0m mask \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mneighbours\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprevious_node_neighbours\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    501\u001B[0m weights[\u001B[38;5;241m~\u001B[39mmask] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m iq\n\u001B[1;32m    503\u001B[0m choice \u001B[38;5;241m=\u001B[39m naive_weighted_choices(rs, weights)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36misin\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/numpy/lib/arraysetops.py:735\u001B[0m, in \u001B[0;36misin\u001B[0;34m(element, test_elements, assume_unique, invert)\u001B[0m\n\u001B[1;32m    642\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    643\u001B[0m \u001B[38;5;124;03mCalculates `element in test_elements`, broadcasting over `element` only.\u001B[39;00m\n\u001B[1;32m    644\u001B[0m \u001B[38;5;124;03mReturns a boolean array of the same shape as `element` that is True\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;124;03m       [ True, False]])\u001B[39;00m\n\u001B[1;32m    733\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    734\u001B[0m element \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(element)\n\u001B[0;32m--> 735\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43min1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_elements\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43massume_unique\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43massume_unique\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    736\u001B[0m \u001B[43m            \u001B[49m\u001B[43minvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minvert\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(element\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[0;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36min1d\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/graph-classification-experiments-RDFHJCIl-py3.8/lib/python3.8/site-packages/numpy/lib/arraysetops.py:607\u001B[0m, in \u001B[0;36min1d\u001B[0;34m(ar1, ar2, assume_unique, invert)\u001B[0m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    606\u001B[0m     mask \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mlen\u001B[39m(ar1), dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mbool\u001B[39m)\n\u001B[0;32m--> 607\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m ar2:\n\u001B[1;32m    608\u001B[0m         mask \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m (ar1 \u001B[38;5;241m==\u001B[39m a)\n\u001B[1;32m    609\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mask\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cora_stellar, cora_labels = get_cora_graph()\n",
    "\n",
    "n_values = [100]\n",
    "length_values = [3]\n",
    "p_values = np.append(np.arange(0.1, 1.0, 0.2), np.arange(1.0, 10.0, 2.0))\n",
    "q_values = np.append(np.arange(0.1, 1.0, 0.2), np.arange(1.0, 10.0, 2.0))\n",
    "# p_values = [1.0, 3.0, 5.0, 7.0]\n",
    "# q_values = [1.0]\n",
    "experiment_results_table = experiment(cora_stellar, cora_labels, q_values=q_values, p_values=p_values, n_values=n_values, length_values=length_values, classification_repeats=10, embedding_size=64)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "    embedding size     p     q  accuracy (mean)  accuracy (std)  \\\n0            128.0   0.1   0.1         0.810322        0.018097   \n1            128.0   0.3   0.1         0.796917        0.003351   \n2            128.0   0.6   0.1         0.793566        0.018767   \n3            128.0   1.0   0.1         0.808311        0.002681   \n4            128.0   5.0   0.1         0.788204        0.004021   \n5            128.0  10.0   0.1         0.794906        0.001340   \n6            128.0   0.1   0.3         0.776139        0.012064   \n7            128.0   0.3   0.3         0.781501        0.014745   \n8            128.0   0.6   0.3         0.799598        0.002011   \n9            128.0   1.0   0.3         0.820375        0.013405   \n10           128.0   5.0   0.3         0.806300        0.018097   \n11           128.0  10.0   0.3         0.810322        0.012735   \n12           128.0   0.1   0.6         0.786193        0.008713   \n13           128.0   0.3   0.6         0.818365        0.004692   \n14           128.0   0.6   0.6         0.808981        0.011394   \n15           128.0   1.0   0.6         0.805630        0.008043   \n16           128.0   5.0   0.6         0.792895        0.018097   \n17           128.0  10.0   0.6         0.797587        0.001340   \n18           128.0   0.1   1.0         0.747989        0.005362   \n19           128.0   0.3   1.0         0.803619        0.004692   \n20           128.0   0.6   1.0         0.804290        0.002681   \n21           128.0   1.0   1.0         0.796917        0.000670   \n22           128.0   5.0   1.0         0.817694        0.006702   \n23           128.0  10.0   1.0         0.795576        0.010054   \n24           128.0   0.1   5.0         0.711126        0.016756   \n25           128.0   0.3   5.0         0.763405        0.003351   \n26           128.0   0.6   5.0         0.760054        0.001340   \n27           128.0   1.0   5.0         0.780161        0.004021   \n28           128.0   5.0   5.0         0.799598        0.004692   \n29           128.0  10.0   5.0         0.790214        0.008713   \n30           128.0   0.1  10.0         0.684987        0.002681   \n31           128.0   0.3  10.0         0.715147        0.020777   \n32           128.0   0.6  10.0         0.722520        0.008043   \n33           128.0   1.0  10.0         0.750670        0.002681   \n34           128.0   5.0  10.0         0.793566        0.002681   \n35           128.0  10.0  10.0         0.795576        0.006032   \n\n    f1_micro (mean)  f1_micro (std)  f1_macro (mean)  f1_macro (std)  \n0          0.810322        0.018097         0.785000        0.017708  \n1          0.796917        0.003351         0.785629        0.002885  \n2          0.793566        0.018767         0.775507        0.019198  \n3          0.808311        0.002681         0.794636        0.006345  \n4          0.788204        0.004021         0.770173        0.003809  \n5          0.794906        0.001340         0.778532        0.004001  \n6          0.776139        0.012064         0.763971        0.012381  \n7          0.781501        0.014745         0.765823        0.017729  \n8          0.799598        0.002011         0.777221        0.006220  \n9          0.820375        0.013405         0.792172        0.008481  \n10         0.806300        0.018097         0.782161        0.013151  \n11         0.810322        0.012735         0.800300        0.016859  \n12         0.786193        0.008713         0.769281        0.013661  \n13         0.818365        0.004692         0.805267        0.000738  \n14         0.808981        0.011394         0.788001        0.008757  \n15         0.805630        0.008043         0.784210        0.001271  \n16         0.792895        0.018097         0.778436        0.017078  \n17         0.797587        0.001340         0.775971        0.001618  \n18         0.747989        0.005362         0.733818        0.005191  \n19         0.803619        0.004692         0.790621        0.005624  \n20         0.804290        0.002681         0.784048        0.003790  \n21         0.796917        0.000670         0.779845        0.002834  \n22         0.817694        0.006702         0.801295        0.004707  \n23         0.795576        0.010054         0.784204        0.016989  \n24         0.711126        0.016756         0.690922        0.019345  \n25         0.763405        0.003351         0.755359        0.001479  \n26         0.760054        0.001340         0.742647        0.006609  \n27         0.780161        0.004021         0.764933        0.009951  \n28         0.799598        0.004692         0.782288        0.004588  \n29         0.790214        0.008713         0.772679        0.010057  \n30         0.684987        0.002681         0.675148        0.008551  \n31         0.715147        0.020777         0.697348        0.020425  \n32         0.722520        0.008043         0.710982        0.002029  \n33         0.750670        0.002681         0.738597        0.007980  \n34         0.793566        0.002681         0.767054        0.006906  \n35         0.795576        0.006032         0.790631        0.007669  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>embedding size</th>\n      <th>p</th>\n      <th>q</th>\n      <th>accuracy (mean)</th>\n      <th>accuracy (std)</th>\n      <th>f1_micro (mean)</th>\n      <th>f1_micro (std)</th>\n      <th>f1_macro (mean)</th>\n      <th>f1_macro (std)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>0.1</td>\n      <td>0.810322</td>\n      <td>0.018097</td>\n      <td>0.810322</td>\n      <td>0.018097</td>\n      <td>0.785000</td>\n      <td>0.017708</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.796917</td>\n      <td>0.003351</td>\n      <td>0.796917</td>\n      <td>0.003351</td>\n      <td>0.785629</td>\n      <td>0.002885</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.793566</td>\n      <td>0.018767</td>\n      <td>0.793566</td>\n      <td>0.018767</td>\n      <td>0.775507</td>\n      <td>0.019198</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>0.1</td>\n      <td>0.808311</td>\n      <td>0.002681</td>\n      <td>0.808311</td>\n      <td>0.002681</td>\n      <td>0.794636</td>\n      <td>0.006345</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>0.1</td>\n      <td>0.788204</td>\n      <td>0.004021</td>\n      <td>0.788204</td>\n      <td>0.004021</td>\n      <td>0.770173</td>\n      <td>0.003809</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>0.1</td>\n      <td>0.794906</td>\n      <td>0.001340</td>\n      <td>0.794906</td>\n      <td>0.001340</td>\n      <td>0.778532</td>\n      <td>0.004001</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>0.3</td>\n      <td>0.776139</td>\n      <td>0.012064</td>\n      <td>0.776139</td>\n      <td>0.012064</td>\n      <td>0.763971</td>\n      <td>0.012381</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>0.781501</td>\n      <td>0.014745</td>\n      <td>0.781501</td>\n      <td>0.014745</td>\n      <td>0.765823</td>\n      <td>0.017729</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>0.3</td>\n      <td>0.799598</td>\n      <td>0.002011</td>\n      <td>0.799598</td>\n      <td>0.002011</td>\n      <td>0.777221</td>\n      <td>0.006220</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>0.3</td>\n      <td>0.820375</td>\n      <td>0.013405</td>\n      <td>0.820375</td>\n      <td>0.013405</td>\n      <td>0.792172</td>\n      <td>0.008481</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>0.3</td>\n      <td>0.806300</td>\n      <td>0.018097</td>\n      <td>0.806300</td>\n      <td>0.018097</td>\n      <td>0.782161</td>\n      <td>0.013151</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>0.3</td>\n      <td>0.810322</td>\n      <td>0.012735</td>\n      <td>0.810322</td>\n      <td>0.012735</td>\n      <td>0.800300</td>\n      <td>0.016859</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>0.6</td>\n      <td>0.786193</td>\n      <td>0.008713</td>\n      <td>0.786193</td>\n      <td>0.008713</td>\n      <td>0.769281</td>\n      <td>0.013661</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>0.6</td>\n      <td>0.818365</td>\n      <td>0.004692</td>\n      <td>0.818365</td>\n      <td>0.004692</td>\n      <td>0.805267</td>\n      <td>0.000738</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>0.6</td>\n      <td>0.808981</td>\n      <td>0.011394</td>\n      <td>0.808981</td>\n      <td>0.011394</td>\n      <td>0.788001</td>\n      <td>0.008757</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>0.6</td>\n      <td>0.805630</td>\n      <td>0.008043</td>\n      <td>0.805630</td>\n      <td>0.008043</td>\n      <td>0.784210</td>\n      <td>0.001271</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>0.6</td>\n      <td>0.792895</td>\n      <td>0.018097</td>\n      <td>0.792895</td>\n      <td>0.018097</td>\n      <td>0.778436</td>\n      <td>0.017078</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>0.6</td>\n      <td>0.797587</td>\n      <td>0.001340</td>\n      <td>0.797587</td>\n      <td>0.001340</td>\n      <td>0.775971</td>\n      <td>0.001618</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.747989</td>\n      <td>0.005362</td>\n      <td>0.747989</td>\n      <td>0.005362</td>\n      <td>0.733818</td>\n      <td>0.005191</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>1.0</td>\n      <td>0.803619</td>\n      <td>0.004692</td>\n      <td>0.803619</td>\n      <td>0.004692</td>\n      <td>0.790621</td>\n      <td>0.005624</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>1.0</td>\n      <td>0.804290</td>\n      <td>0.002681</td>\n      <td>0.804290</td>\n      <td>0.002681</td>\n      <td>0.784048</td>\n      <td>0.003790</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.796917</td>\n      <td>0.000670</td>\n      <td>0.796917</td>\n      <td>0.000670</td>\n      <td>0.779845</td>\n      <td>0.002834</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>0.817694</td>\n      <td>0.006702</td>\n      <td>0.817694</td>\n      <td>0.006702</td>\n      <td>0.801295</td>\n      <td>0.004707</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>1.0</td>\n      <td>0.795576</td>\n      <td>0.010054</td>\n      <td>0.795576</td>\n      <td>0.010054</td>\n      <td>0.784204</td>\n      <td>0.016989</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>5.0</td>\n      <td>0.711126</td>\n      <td>0.016756</td>\n      <td>0.711126</td>\n      <td>0.016756</td>\n      <td>0.690922</td>\n      <td>0.019345</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>5.0</td>\n      <td>0.763405</td>\n      <td>0.003351</td>\n      <td>0.763405</td>\n      <td>0.003351</td>\n      <td>0.755359</td>\n      <td>0.001479</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>5.0</td>\n      <td>0.760054</td>\n      <td>0.001340</td>\n      <td>0.760054</td>\n      <td>0.001340</td>\n      <td>0.742647</td>\n      <td>0.006609</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.780161</td>\n      <td>0.004021</td>\n      <td>0.780161</td>\n      <td>0.004021</td>\n      <td>0.764933</td>\n      <td>0.009951</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.799598</td>\n      <td>0.004692</td>\n      <td>0.799598</td>\n      <td>0.004692</td>\n      <td>0.782288</td>\n      <td>0.004588</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>5.0</td>\n      <td>0.790214</td>\n      <td>0.008713</td>\n      <td>0.790214</td>\n      <td>0.008713</td>\n      <td>0.772679</td>\n      <td>0.010057</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>128.0</td>\n      <td>0.1</td>\n      <td>10.0</td>\n      <td>0.684987</td>\n      <td>0.002681</td>\n      <td>0.684987</td>\n      <td>0.002681</td>\n      <td>0.675148</td>\n      <td>0.008551</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>128.0</td>\n      <td>0.3</td>\n      <td>10.0</td>\n      <td>0.715147</td>\n      <td>0.020777</td>\n      <td>0.715147</td>\n      <td>0.020777</td>\n      <td>0.697348</td>\n      <td>0.020425</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>128.0</td>\n      <td>0.6</td>\n      <td>10.0</td>\n      <td>0.722520</td>\n      <td>0.008043</td>\n      <td>0.722520</td>\n      <td>0.008043</td>\n      <td>0.710982</td>\n      <td>0.002029</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>128.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>0.750670</td>\n      <td>0.002681</td>\n      <td>0.750670</td>\n      <td>0.002681</td>\n      <td>0.738597</td>\n      <td>0.007980</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>128.0</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>0.793566</td>\n      <td>0.002681</td>\n      <td>0.793566</td>\n      <td>0.002681</td>\n      <td>0.767054</td>\n      <td>0.006906</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>128.0</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.795576</td>\n      <td>0.006032</td>\n      <td>0.795576</td>\n      <td>0.006032</td>\n      <td>0.790631</td>\n      <td>0.007669</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cora_stellar, cora_labels = get_cora_graph()\n",
    "\n",
    "n_values = [100]\n",
    "length_values = [5]\n",
    "q_values = np.array([0.1, 0.3, 0.6, 1.0, 5.0, 10.0])\n",
    "p_values = np.array([0.1, 0.3, 0.6, 1.0, 5.0, 10.0])\n",
    "experiment_results_table = experiment(cora_stellar, cora_labels, q_values=q_values, p_values=p_values, n_values=n_values, length_values=length_values, classification_repeats=3, embedding_size=128, split=1)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display(experiment_results_table)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rr/p4lmjn152vj75lt21_txptlh0000gn/T/ipykernel_40687/1254143326.py:4: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  experiment_results_table.to_latex('./cora-results-n20-l3.tex')\n"
     ]
    }
   ],
   "source": [
    "experiment_results_table.to_excel('./cora-results-n100-l5.xlsx')\n",
    "experiment_results_table.to_pickle('./cora-results-n100-l5.pkl')\n",
    "experiment_results_table.to_csv('./cora-results-n100-l5.csv')\n",
    "experiment_results_table.to_latex('./cora-results-n100-l5.tex')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link_classification: using 'dot' method to combine node embeddings into edge embeddings\n",
      "Epoch 1/2\n",
      "3976/3976 [==============================] - 7s 2ms/step - loss: 0.6195 - binary_accuracy: 0.6349\n",
      "Epoch 2/2\n",
      "3976/3976 [==============================] - 7s 2ms/step - loss: 0.5143 - binary_accuracy: 0.7126\n",
      "50/50 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "word2vec_results: Word2VecResult = word2vec_run(cora_stellar, n=20, length=3, p=0.5, q=0.5, embedding_size=64, verbose=1)\n",
    "experiment_balanced_embeddings, experiment_balanced_labels = balance(word2vec_results.embeddings, cora_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}